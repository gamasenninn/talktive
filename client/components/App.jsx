import { useEffect, useRef, useState, useCallback } from "react";
import logo from "/assets/openai-logomark.svg";
import EventLog from "./EventLog";
import SessionControls from "./SessionControls";
import ToolPanel from "./ToolPanel";

export default function App() {
  const [isSessionActive, setIsSessionActive] = useState(false);
  const [events, setEvents] = useState([]);
  const [dataChannel, setDataChannel] = useState(null);
  const [isPushToTalkEnabled, setIsPushToTalkEnabled] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const peerConnection = useRef(null);
  const audioElement = useRef(null);
  const localStream = useRef(null);
  const spaceKeyTimer = useRef(null);
  const isRecordingRef = useRef(false);
  const defaultModel = import.meta.env.VITE_OPENAI_MODEL || "gpt-4o-realtime-preview-2024-12-17";
  const [selectedModel, setSelectedModel] = useState(defaultModel);
  
  // ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Push-to-Talkåˆ¶é™æ™‚é–“ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5ç§’ï¼‰
  const pushToTalkTimeLimit = parseInt(import.meta.env.VITE_PUSH_TO_TALK_TIME_LIMIT) || 5000;
  
  // ç’°å¢ƒå¤‰æ•°ã‹ã‚‰VADã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰è¨­å®šã‚’å–å¾—
  const vadThresholdDefault = parseFloat(import.meta.env.VITE_VAD_THRESHOLD_DEFAULT) || 0.5;
  const vadThresholdMin = parseFloat(import.meta.env.VITE_VAD_THRESHOLD_MIN) || 0.0;
  const vadThresholdMax = parseFloat(import.meta.env.VITE_VAD_THRESHOLD_MAX) || 1.0;
  const vadThresholdStep = parseFloat(import.meta.env.VITE_VAD_THRESHOLD_STEP) || 0.01;
  
  // VADã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰ã®åˆæœŸå€¤ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®š
  const [vadThreshold, setVadThreshold] = useState(vadThresholdDefault);

  // Send a message to the model
  const sendClientEvent = useCallback((message) => {
    if (dataChannel) {
      const timestamp = new Date().toLocaleTimeString();
      const messageWithId = {
        ...message,
        event_id: message.event_id || crypto.randomUUID()
      };

      // send event before setting timestamp since the backend peer doesn't expect this field
      dataChannel.send(JSON.stringify(messageWithId));
      console.log("ğŸ“¤ Sent event:", messageWithId.type);

      // if guard just in case the timestamp exists by miracle
      if (!messageWithId.timestamp) {
        messageWithId.timestamp = timestamp;
      }
      setEvents((prev) => [messageWithId, ...prev]);
    } else {
      console.error(
        "Failed to send message - no data channel available",
        message,
      );
    }
  }, [dataChannel]);

  // ãƒã‚¤ã‚¯ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
  const toggleMicrophone = useCallback((enabled) => {
    if (localStream.current) {
      const audioTrack = localStream.current.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = enabled;
        console.log(`ğŸ¤ Microphone ${enabled ? 'enabled' : 'disabled'}`);
      } else {
        console.log("âŒ No audio track found");
      }
    } else {
      console.log("âŒ No local stream found");
    }
  }, []);

  // VADè¨­å®šã‚’é€ä¿¡ã™ã‚‹é–¢æ•°
  const updateVADSettings = useCallback(() => {
    if (dataChannel && dataChannel.readyState === 'open' && !isPushToTalkEnabled) {
      console.log(`ğŸ›ï¸ Updating VAD threshold to: ${vadThreshold} (env default: ${vadThresholdDefault})`);
      const vadEvent = {
        type: "session.update",
        session: {
          input_audio_transcription: {
            model: "whisper-1"
          },
          turn_detection: {
            type: "server_vad",
            threshold: vadThreshold,
            prefix_padding_ms: 300,
            silence_duration_ms: vadThreshold > 0.7 ? 1000 : 500 // é«˜ã„ã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰æ™‚ã¯é•·ã„ç„¡éŸ³æ™‚é–“
          }
        }
      };
      
      sendClientEvent(vadEvent);
      console.log(`âœ… VAD settings sent: threshold=${vadThreshold}, silence_duration=${vadThreshold > 0.7 ? 1000 : 500}ms`);
    } else {
      console.log(`âŒ Cannot update VAD settings - Push-to-Talk: ${isPushToTalkEnabled}, DataChannel: ${dataChannel?.readyState}`);
    }
  }, [dataChannel, vadThreshold, sendClientEvent, isPushToTalkEnabled, vadThresholdDefault]);

  // éŒ²éŸ³åœæ­¢
  const stopRecording = useCallback(() => {
    if (!isRecordingRef.current) {
      console.log("âš ï¸ stopRecording called but not recording");
      return;
    }
    
    console.log("ğŸ“¢ stopRecording called");
    
    // ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (spaceKeyTimer.current) {
      clearTimeout(spaceKeyTimer.current);
      spaceKeyTimer.current = null;
    }
    
    isRecordingRef.current = false;
    setIsRecording(false);
    
    // ãƒã‚¤ã‚¯ã‚’ç„¡åŠ¹ã«ã™ã‚‹
    toggleMicrophone(false);
    
    // OpenAI Realtime APIã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆã‚’è¦æ±‚
    sendClientEvent({
      type: "response.create"
    });
    
    console.log("ğŸ›‘ Recording stopped");
  }, [toggleMicrophone, sendClientEvent]);

  // éŒ²éŸ³é–‹å§‹
  const startRecording = useCallback(() => {
    if (!isSessionActive || !dataChannel || isRecordingRef.current) {
      console.log("âŒ Cannot start recording:", { isSessionActive, hasDataChannel: !!dataChannel, isRecording: isRecordingRef.current });
      return;
    }
    
    console.log("ğŸ“¢ startRecording called");
    isRecordingRef.current = true;
    setIsRecording(true);
    
    // ãƒã‚¤ã‚¯ã‚’æœ‰åŠ¹ã«ã™ã‚‹
    toggleMicrophone(true);
    
    // ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã•ã‚ŒãŸæ™‚é–“å¾Œã«è‡ªå‹•çš„ã«åœæ­¢ã™ã‚‹ã‚¿ã‚¤ãƒãƒ¼ã‚’è¨­å®šï¼ˆå®‰å…¨è£…ç½®ï¼‰
    if (spaceKeyTimer.current) {
      clearTimeout(spaceKeyTimer.current);
    }
    spaceKeyTimer.current = setTimeout(() => {
      console.log(`â° Timer: Auto-stopping recording after ${pushToTalkTimeLimit}ms`);
      stopRecording();
    }, pushToTalkTimeLimit);
    
    console.log(`âœ… Recording started (auto-stop in ${pushToTalkTimeLimit}ms)`);
  }, [isSessionActive, dataChannel, toggleMicrophone, stopRecording, pushToTalkTimeLimit]);

  // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†
  useEffect(() => {
    if (!isPushToTalkEnabled || !isSessionActive) {
      console.log("ğŸš« Keyboard events disabled", { isPushToTalkEnabled, isSessionActive });
      return;
    }

    console.log("ğŸ¯ Setting up keyboard events");

    const handleKeyDown = (event) => {
      console.log("âŒ¨ï¸ Key down:", event.code, "Repeat:", event.repeat, "Recording:", isRecordingRef.current);
      
      if (event.code === 'Space' && !event.repeat && !isRecordingRef.current) {
        event.preventDefault();
        console.log("ğŸ”´ Space DOWN - calling startRecording");
        startRecording();
      }
    };

    const handleKeyUp = (event) => {
      console.log("âŒ¨ï¸ Key up:", event.code, "Recording:", isRecordingRef.current);
      
      if (event.code === 'Space' && isRecordingRef.current) {
        event.preventDefault();
        console.log("ğŸ”µ Space UP - calling stopRecording");
        stopRecording();
      }
    };

    // windowã¨documentã®ä¸¡æ–¹ã«ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’è¿½åŠ 
    window.addEventListener('keydown', handleKeyDown, true);
    window.addEventListener('keyup', handleKeyUp, true);
    document.addEventListener('keydown', handleKeyDown, true);
    document.addEventListener('keyup', handleKeyUp, true);

    return () => {
      console.log("ğŸ§¹ Cleaning up keyboard events");
      window.removeEventListener('keydown', handleKeyDown, true);
      window.removeEventListener('keyup', handleKeyUp, true);
      document.removeEventListener('keydown', handleKeyDown, true);
      document.removeEventListener('keyup', handleKeyUp, true);
      
      // ã‚¿ã‚¤ãƒãƒ¼ã‚‚ã‚¯ãƒªã‚¢
      if (spaceKeyTimer.current) {
        clearTimeout(spaceKeyTimer.current);
        spaceKeyTimer.current = null;
      }
    };
  }, [isPushToTalkEnabled, isSessionActive, startRecording, stopRecording]);

  // Push-to-Talkãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ
  const togglePushToTalk = useCallback(() => {
    const newMode = !isPushToTalkEnabled;
    setIsPushToTalkEnabled(newMode);
    
    console.log("ğŸ”„ Push-to-Talk mode:", newMode);
    
    // éŒ²éŸ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    isRecordingRef.current = false;
    setIsRecording(false);
    
    if (spaceKeyTimer.current) {
      clearTimeout(spaceKeyTimer.current);
      spaceKeyTimer.current = null;
    }
    
    if (newMode) {
      // Push-to-Talkãƒ¢ãƒ¼ãƒ‰: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒã‚¤ã‚¯ã‚’ç„¡åŠ¹ã«ã™ã‚‹
      toggleMicrophone(false);
    } else {
      // å¸¸æ™‚éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰: ãƒã‚¤ã‚¯ã‚’æœ‰åŠ¹ã«ã™ã‚‹
      toggleMicrophone(true);
    }
  }, [isPushToTalkEnabled, toggleMicrophone]);

  // VADã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒªã‚»ãƒƒãƒˆã™ã‚‹é–¢æ•°
  const resetVadThreshold = useCallback(() => {
    setVadThreshold(vadThresholdDefault);
    console.log(`ğŸ”„ VAD threshold reset to default: ${vadThresholdDefault}`);
  }, [vadThresholdDefault]);

  // VADã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
  const validateAndSetVadThreshold = useCallback((value) => {
    const clampedValue = Math.max(vadThresholdMin, Math.min(vadThresholdMax, value));
    setVadThreshold(clampedValue);
    if (value !== clampedValue) {
      console.warn(`âš ï¸ VAD threshold clamped from ${value} to ${clampedValue} (range: ${vadThresholdMin}-${vadThresholdMax})`);
    }
  }, [vadThresholdMin, vadThresholdMax]);

  async function startSession() {
    console.log("ğŸš€ Starting session...");
    
    // Get a session token for OpenAI Realtime API
    const tokenResponse = await fetch("/token");
    const data = await tokenResponse.json();
    const EPHEMERAL_KEY = data.client_secret.value;

    // Create a peer connection
    const pc = new RTCPeerConnection();

    // Set up to play remote audio from the model
    audioElement.current = document.createElement("audio");
    audioElement.current.autoplay = true;
    audioElement.current.volume = 1.0; // éŸ³é‡ã‚’æ˜ç¤ºçš„ã«è¨­å®š
    console.log("ğŸ”Š Audio element created:", audioElement.current);
    
    pc.ontrack = (e) => {
      console.log("ğŸ“¡ Received audio track:", e.streams[0]);
      audioElement.current.srcObject = e.streams[0];
      console.log("ğŸ”Š Audio source set:", audioElement.current.srcObject);
      
      // éŸ³å£°å†ç”Ÿã‚’å¼·åˆ¶çš„ã«é–‹å§‹
      audioElement.current.play().then(() => {
        console.log("âœ… Audio playback started successfully");
      }).catch((error) => {
        console.error("âŒ Audio playback failed:", error);
      });
    };

    // Add local audio track for microphone input in the browser
    const ms = await navigator.mediaDevices.getUserMedia({
      audio: true,
    });
    
    localStream.current = ms;
    const audioTrack = ms.getTracks()[0];
    
    console.log("ğŸ¤ Audio track created:", audioTrack);
    
    // Push-to-Talkãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªå ´åˆã€æœ€åˆã¯ãƒã‚¤ã‚¯ã‚’ç„¡åŠ¹ã«ã™ã‚‹
    if (isPushToTalkEnabled) {
      audioTrack.enabled = false;
      console.log("ğŸ”‡ Initial microphone disabled (Push-to-Talk mode)");
    }
    
    pc.addTrack(audioTrack);

    // Set up data channel for sending and receiving events
    const dc = pc.createDataChannel("oai-events");
    setDataChannel(dc);

    // Start the session using the Session Description Protocol (SDP)
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const baseUrl = "https://api.openai.com/v1/realtime";
    //const baseUrl = "gpt-4o-mini-realtime-preview-2024-12-17";
    const sdpResponse = await fetch(`${baseUrl}?model=${selectedModel}`, {
      method: "POST",
      body: offer.sdp,
      headers: {
        Authorization: `Bearer ${EPHEMERAL_KEY}`,
        "Content-Type": "application/sdp",
      },
    });

    const answer = {
      type: "answer",
      sdp: await sdpResponse.text(),
    };
    await pc.setRemoteDescription(answer);

    peerConnection.current = pc;
  }

  // Stop current session, clean up peer connection and data channel
  function stopSession() {
    console.log("ğŸ›‘ Stopping session...");
    
    // ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (spaceKeyTimer.current) {
      clearTimeout(spaceKeyTimer.current);
      spaceKeyTimer.current = null;
    }
    
    // éŒ²éŸ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    isRecordingRef.current = false;
    setIsRecording(false);
    
    if (dataChannel) {
      dataChannel.close();
    }

    if (localStream.current) {
      localStream.current.getTracks().forEach(track => track.stop());
      localStream.current = null;
    }

    if (peerConnection.current) {
      peerConnection.current.getSenders().forEach((sender) => {
        if (sender.track) {
          sender.track.stop();
        }
      });
      peerConnection.current.close();
    }

    setIsSessionActive(false);
    setDataChannel(null);
    peerConnection.current = null;
  }

  // Send a text message to the model
  const sendTextMessage = useCallback((message) => {
    const event = {
      type: "conversation.item.create",
      item: {
        type: "message",
        role: "user",
        content: [
          {
            type: "input_text",
            text: message,
          },
        ],
      },
    };

    sendClientEvent(event);
    sendClientEvent({ type: "response.create" });
  }, [sendClientEvent]);

  // Attach event listeners to the data channel when a new one is created
  useEffect(() => {
    if (dataChannel) {
      // Append new server events to the list
      dataChannel.addEventListener("message", (e) => {
        const event = JSON.parse(e.data);
        if (!event.timestamp) {
          event.timestamp = new Date().toLocaleTimeString();
        }

        setEvents((prev) => [event, ...prev]);
      });

      // Set session active when the data channel is opened
      dataChannel.addEventListener("open", () => {
        console.log("ğŸ”— Data channel opened");
        setIsSessionActive(true);
        setEvents([]);
        // ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ãƒãƒ«ãŒé–‹ã„ãŸã‚‰VADè¨­å®šã‚’é€ä¿¡
        setTimeout(() => {
          updateVADSettings();
        }, 100);
      });
    }
  }, [dataChannel, updateVADSettings]);

  // VADã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰ãŒå¤‰æ›´ã•ã‚ŒãŸã¨ãã«è¨­å®šã‚’æ›´æ–°
  useEffect(() => {
    if (isSessionActive) {
      updateVADSettings();
    }
  }, [vadThreshold, isSessionActive, updateVADSettings]);

  // æ„Ÿåº¦ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®šé–¢æ•°
  const getSensitivityLevel = (threshold) => {
    if (threshold <= 0.2) return "è¶…é«˜æ„Ÿåº¦";
    if (threshold <= 0.5) return "é«˜æ„Ÿåº¦";
    if (threshold <= 0.8) return "ä¸­æ„Ÿåº¦";
    if (threshold < 0.95) return "ä½æ„Ÿåº¦";
    if (threshold < 1.0) return "è¶…ä½æ„Ÿåº¦ãƒ»è¦èª¿æ•´";
    return "ç„¡åŠ¹";
  };

  return (
    <>
      <nav className="absolute top-0 left-0 right-0 h-16 flex items-center">
        <div className="flex items-center gap-4 w-full m-4 pb-2 border-0 border-b border-solid border-gray-200">
          <img style={{ width: "24px" }} src={logo} />
          <h1>realtime console</h1>
          
          {/* Push-to-Talkåˆ¶å¾¡ãƒ‘ãƒãƒ« */}
          <div className="ml-auto flex items-center gap-4">
            <label className="flex items-center gap-2">
              <input
                type="checkbox"
                checked={isPushToTalkEnabled}
                onChange={togglePushToTalk}
                disabled={isSessionActive}
              />
              <span className="text-sm">Push-to-Talk ãƒ¢ãƒ¼ãƒ‰</span>
            </label>
            
            {isPushToTalkEnabled && (
              <div className="flex items-center gap-2">
                <div className={`w-3 h-3 rounded-full ${isRecording ? 'bg-red-500' : 'bg-gray-300'}`}></div>
                <span className="text-sm">
                  {isRecording ? `éŒ²éŸ³ä¸­ï¼ˆ${pushToTalkTimeLimit/1000}ç§’ã§è‡ªå‹•åœæ­¢ï¼‰` : 'ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦è©±ã™'}
                </span>
              </div>
            )}
          </div>
        </div>
      </nav>
      
      <main className="absolute top-16 left-0 right-0 bottom-0">
        <section className="absolute top-0 left-0 right-[380px] bottom-0 flex">
          <section className="absolute top-0 left-0 right-0 bottom-32 px-4 overflow-y-auto">
            <EventLog events={events} />
          </section>
          <section className="absolute h-32 left-0 right-0 bottom-0 p-4">
            <SessionControls
              startSession={startSession}
              stopSession={stopSession}
              sendClientEvent={sendClientEvent}
              sendTextMessage={sendTextMessage}
              events={events}
              isSessionActive={isSessionActive}
              isPushToTalkEnabled={isPushToTalkEnabled}
              isRecording={isRecording}
              startRecording={startRecording}
              stopRecording={stopRecording}
            />
          </section>
        </section>
        <section className="absolute top-0 w-[380px] right-0 bottom-0 p-4 pt-0 overflow-y-auto">
          {/* VADã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰èª¿æ•´UI */}
          <div className="bg-gray-50 rounded-md p-4 mb-4">
            <div className="flex items-center justify-between mb-2">
              <h3 className="text-sm font-semibold">ãƒã‚¤ã‚¯æ„Ÿåº¦è¨­å®š</h3>
              <button
                onClick={resetVadThreshold}
                className="px-2 py-1 text-xs bg-gray-200 hover:bg-gray-300 rounded"
                disabled={isPushToTalkEnabled}
                title={`ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ (${vadThresholdDefault}) ã«ãƒªã‚»ãƒƒãƒˆ`}
              >
                ãƒªã‚»ãƒƒãƒˆ
              </button>
            </div>
            
            {/* ç’°å¢ƒå¤‰æ•°æƒ…å ±è¡¨ç¤º */}
            <div className="bg-blue-50 border border-blue-200 rounded p-2 mb-2">
              <p className="text-xs text-blue-800">
                ğŸ”§ è¨­å®šç¯„å›²: {vadThresholdMin} - {vadThresholdMax} (ã‚¹ãƒ†ãƒƒãƒ—: {vadThresholdStep})
                <br/>
                ğŸ“‹ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤: {vadThresholdDefault}
              </p>
            </div>
            
            {isPushToTalkEnabled && (
              <div className="bg-yellow-100 border border-yellow-300 rounded p-2 mb-2">
                <p className="text-xs text-yellow-800">
                  âš ï¸ Push-to-Talkãƒ¢ãƒ¼ãƒ‰ä¸­ã¯VADè¨­å®šã¯ç„¡åŠ¹ã§ã™
                </p>
              </div>
            )}
            <div className={`flex flex-col gap-2 ${isPushToTalkEnabled ? 'opacity-50' : ''}`}>
              <label className="text-xs text-gray-600">
                VADã‚¹ãƒ¬ãƒƒã‚·ãƒ§ãƒ«ãƒ‰: {vadThreshold.toFixed(2)} ({getSensitivityLevel(vadThreshold)})
              </label>
              <input
                type="range"
                min={vadThresholdMin}
                max={vadThresholdMax}
                step={vadThresholdStep}
                value={vadThreshold}
                onChange={(e) => validateAndSetVadThreshold(parseFloat(e.target.value))}
                className="w-full"
                disabled={isPushToTalkEnabled}
              />
              <div className="flex justify-between text-xs text-gray-500">
                <span>è¶…é«˜æ„Ÿåº¦<br/>{vadThresholdMin}</span>
                <span>ä¸­é–“<br/>{((vadThresholdMax + vadThresholdMin) / 2).toFixed(1)}</span>
                <span>èª¿æ•´ç¯„å›²<br/>{vadThresholdMax}</span>
              </div>
              <p className="text-xs text-gray-600 mt-1">
                ç’°å¢ƒå¤‰æ•°ã§è¨­å®šå¯èƒ½ãªç¯„å›²å†…ã§èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
              </p>
              {vadThreshold >= 0.95 && (
                <div className="bg-blue-50 border border-blue-200 rounded p-2">
                  <p className="text-xs text-blue-800">
                    ğŸ’¡ ç¾åœ¨ã¯è¶…ä½æ„Ÿåº¦åŸŸã§ã™ã€‚0.96-0.99ã§æœ€é©å€¤ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚
                  </p>
                </div>
              )}
              <div className="flex gap-1 mt-2">
                {[0.96, 0.97, 0.98, 0.99, 1.00].filter(val => val >= vadThresholdMin && val <= vadThresholdMax).map(val => (
                  <button
                    key={val}
                    onClick={() => validateAndSetVadThreshold(val)}
                    className={`px-2 py-1 text-xs rounded ${
                      val === 1.00 
                        ? 'bg-red-200 hover:bg-red-300' 
                        : 'bg-gray-200 hover:bg-gray-300'
                    }`}
                    disabled={isPushToTalkEnabled}
                  >
                    {val.toFixed(2)}
                  </button>
                ))}
              </div>
              {isSessionActive && !isPushToTalkEnabled && (
                <button
                  onClick={() => updateVADSettings()}
                  className="mt-2 px-3 py-1 bg-blue-500 text-white text-xs rounded hover:bg-blue-600"
                >
                  è¨­å®šã‚’å†é€ä¿¡
                </button>
              )}
            </div>
          </div>
              
          <ToolPanel
            sendClientEvent={sendClientEvent}
            sendTextMessage={sendTextMessage}
            events={events}
            isSessionActive={isSessionActive}
          />
        </section>
      </main>
    </>
  );
}